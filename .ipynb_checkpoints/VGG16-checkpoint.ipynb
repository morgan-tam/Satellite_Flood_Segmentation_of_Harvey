{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "import shapely.geometry\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py # just a safety check so the checkpoint callback doesnt crash\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = 'training_tiles/'\n",
    "np_files = [os.path.join(path,f[:f.find('_img.npy')])\n",
    "             for path,_,files in os.walk(dir_path) \n",
    "             for f in files if (f.endswith('img.npy'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_bands(img, lower_pct = 1, upper_pct = 99):\n",
    "    \"\"\"\n",
    "    Rescale the bands of a multichannel image for display\n",
    "    \"\"\"\n",
    "    # Loop through the image bands, rescaling each one\n",
    "    img_scaled = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    for i in range(img.shape[2]):\n",
    "        \n",
    "        band = img[:, :, i]\n",
    "        \n",
    "        # Pick out the lower and upper percentiles\n",
    "        lower, upper = np.percentile(band, [lower_pct, upper_pct])\n",
    "        \n",
    "        # Normalize the band\n",
    "        band = (band - lower) / (upper - lower) * 255\n",
    "        \n",
    "        # Clip the high and low values, and cast to uint8\n",
    "        img_scaled[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "        \n",
    "    return img_scaled\n",
    "\n",
    "def resize(img, new_shape):\n",
    "    img_resized = np.zeros(new_shape+(img.shape[2],)).astype('float32')\n",
    "    for i in range(img.shape[2]):\n",
    "        img_resized[:, :, i] = imresize(img[:, :, i], new_shape, interp='bicubic')\n",
    "    return img_resized\n",
    "\n",
    "def make_set(files, training_size, test_size,input_size):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    maskz = []\n",
    "    tile_to_use = np.random.choice(files, size=(training_size+test_size), replace=False)\n",
    "    for tile_no in tile_to_use:\n",
    "        img = np.load(tile_no +'_img.npy')\n",
    "        img = resize(img, (input_size, input_size))\n",
    "        \n",
    "        mask = np.load(tile_no +'_mask.npy')\n",
    "        mask = imresize(mask, (input_size, input_size))\n",
    "        \n",
    "        maskz = mask[..., None]\n",
    "        #maskz = np.concatenate(mask[..., None], axis=2)\n",
    "        \n",
    "        X.append(img[None,...])\n",
    "        Y.append(maskz[None,...])\n",
    "    \n",
    "    # Concatenate the results\n",
    "    X = np.concatenate(X, axis = 0)\n",
    "    Y = np.concatenate(Y, axis = 0)\n",
    "    \n",
    "    # Normalize the values\n",
    "    X = X.astype('float32')\n",
    "    X = (X / X.max() - 0.5) * 2   # put X in range [-1, 1]\n",
    "    Y = Y.astype('float32') / 255 # put Y in range [0, 1]\n",
    "    \n",
    "    test_size = test_size/float(training_size+test_size)\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 256\n",
    "X_train, Y_train, X_val, Y_val = make_set(np_files, 6000, 500, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, Lambda, Add, Reshape, ZeroPadding2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend.tensorflow_backend\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "# Clear any junk from session memory\n",
    "K.clear_session()\n",
    "\n",
    "# Set network size params\n",
    "N_CLASSES = 1\n",
    "N_CHANNEL = 3\n",
    "INPUT_SIZE = 256\n",
    "\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "\n",
    "\n",
    "# Define metrics\n",
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return - dice_coef(y_true, y_pred)\n",
    "\n",
    "def jacc_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "def jacc_coef_loss(y_true, y_pred):\n",
    "    return -jacc_coef(y_true, y_pred)\n",
    "\n",
    "def jacc_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "def mean_pixel_intersection_over_union(y_true, y_pred):\n",
    "    tp = np.sum((y_pred > 0.15) & (y_true > 0.15))\n",
    "    tn = np.sum((y_pred < 0.15) & (y_true < 0.15))\n",
    "    fp = np.sum((y_pred > 0.15) & (y_true < 0.15))\n",
    "    fn = np.sum((y_pred < 0.15) & (y_true > 0.15))\n",
    "    return K.mean(tp/(tp+fp+fn))\n",
    "\n",
    "\n",
    "def fcn_model(lr=.001):\n",
    "    K.clear_session()\n",
    "    \n",
    "    img_input = Input((INPUT_SIZE, INPUT_SIZE, N_CHANNEL))\n",
    "        \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    x = Dropout(0.5)(pool3)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(pool3)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    x = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(pool4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    x = Dropout(0.5)(pool5)\n",
    "\n",
    "    x = Conv2D(4096, (7, 7), activation='relu', padding='same')(pool5)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(4096, (1, 1), activation='relu', padding='same')(x)\n",
    "    drop = Dropout(0.5)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    score_c5 = Conv2D(N_CLASSES, (1, 1), strides=(1, 1), padding='same', kernel_initializer='zeros')(drop)\n",
    "    up_c5 = Conv2DTranspose(N_CLASSES, (2, 2), strides=(2, 2), padding='valid')(score_c5)\n",
    "    \n",
    "    score_c4 = Conv2D(N_CLASSES, (1, 1), strides=(1, 1), padding='same', kernel_initializer='zeros')(pool4)\n",
    "    fuse_16 = Add()([score_c4, up_c5])\n",
    "    up_c4 = Conv2DTranspose(N_CLASSES, (2, 2), strides=(2, 2), padding='valid')(fuse_16)\n",
    "    \n",
    "    score_c3 = Conv2D(N_CLASSES, (1, 1), strides=(1, 1), padding='same', kernel_initializer='zeros')(pool3)\n",
    "    fuse_32 = Add()([score_c3, up_c4])\n",
    "    up_c3 = Conv2DTranspose(N_CLASSES, (8, 8), strides=(8, 8), padding='valid', activation='sigmoid')(fuse_32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #fcn_model = Sequential()\n",
    "    fcn_model = Model(inputs=img_input, outputs=up_c3)\n",
    "    \n",
    "    #fcn_model.load_weights(weights_path, by_name=True)\n",
    "    fcn_model.load_weights(os.path.join('checkpoints_ffip_fcn_vgg', 'newFIXEDweights.20-0.33755.hdf5'), by_name=False)\n",
    "    \n",
    "    fcn_model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=[jacc_coef])\n",
    "    \n",
    "    return fcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 500 samples\n",
      "Epoch 1/80\n",
      "6000/6000 [==============================] - 268s - loss: 0.3359 - jacc_coef: 0.4566 - val_loss: 0.3458 - val_jacc_coef: 0.4466\n",
      "Epoch 2/80\n",
      "6000/6000 [==============================] - 267s - loss: 0.3324 - jacc_coef: 0.4614 - val_loss: 0.3439 - val_jacc_coef: 0.4349\n",
      "Epoch 3/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3316 - jacc_coef: 0.4641 - val_loss: 0.3459 - val_jacc_coef: 0.4446\n",
      "Epoch 4/80\n",
      "6000/6000 [==============================] - 268s - loss: 0.3279 - jacc_coef: 0.4678 - val_loss: 0.3416 - val_jacc_coef: 0.4366\n",
      "Epoch 5/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3268 - jacc_coef: 0.4716 - val_loss: 0.3602 - val_jacc_coef: 0.4128\n",
      "Epoch 6/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3257 - jacc_coef: 0.4715 - val_loss: 0.3506 - val_jacc_coef: 0.4312\n",
      "Epoch 7/80\n",
      "6000/6000 [==============================] - 269s - loss: 0.3227 - jacc_coef: 0.4728 - val_loss: 0.3407 - val_jacc_coef: 0.4399\n",
      "Epoch 8/80\n",
      "6000/6000 [==============================] - 269s - loss: 0.3193 - jacc_coef: 0.4772 - val_loss: 0.3403 - val_jacc_coef: 0.4452\n",
      "Epoch 9/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3174 - jacc_coef: 0.4816 - val_loss: 0.3404 - val_jacc_coef: 0.4297\n",
      "Epoch 10/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3161 - jacc_coef: 0.4820 - val_loss: 0.3418 - val_jacc_coef: 0.4446\n",
      "Epoch 11/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3146 - jacc_coef: 0.4874 - val_loss: 0.3410 - val_jacc_coef: 0.4453\n",
      "Epoch 12/80\n",
      "6000/6000 [==============================] - 269s - loss: 0.3116 - jacc_coef: 0.4880 - val_loss: 0.3392 - val_jacc_coef: 0.4587\n",
      "Epoch 13/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3095 - jacc_coef: 0.4908 - val_loss: 0.3430 - val_jacc_coef: 0.4621\n",
      "Epoch 14/80\n",
      "6000/6000 [==============================] - 268s - loss: 0.3067 - jacc_coef: 0.4941 - val_loss: 0.3388 - val_jacc_coef: 0.4494\n",
      "Epoch 15/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3052 - jacc_coef: 0.4934 - val_loss: 0.3461 - val_jacc_coef: 0.4693\n",
      "Epoch 16/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.3005 - jacc_coef: 0.5035 - val_loss: 0.3471 - val_jacc_coef: 0.4630\n",
      "Epoch 17/80\n",
      "6000/6000 [==============================] - 259s - loss: 0.2982 - jacc_coef: 0.5060 - val_loss: 0.3465 - val_jacc_coef: 0.4818\n",
      "Epoch 18/80\n",
      "4632/6000 [======================>.......] - ETA: 57s - loss: 0.2959 - jacc_coef: 0.5091"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "              patience=5, min_lr=0.0000000001)\n",
    "\n",
    "if not os.path.exists('/media/mlt/Passport 2TB/Morgan\\'s Files/Satellite_Roads_Segmentation/checkpoints_ffip_fcn_vgg'):\n",
    "    os.makedirs('/media/mlt/Passport 2TB/Morgan\\'s Files/Satellite_Roads_Segmentation/checkpoints_ffip_fcn_vgg')\n",
    "model_checkpoint = ModelCheckpoint(os.path.join('/media/mlt/Passport 2TB/Morgan\\'s Files/Satellite_Roads_Segmentation/checkpoints_ffip_fcn_vgg', 'newFIXEDweights.{epoch:02d}-{loss:.5f}.hdf5'),\n",
    "                                  monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 80\n",
    "# gen = ImageDataGenerator()\n",
    "# train_batches = gen.flow(X_train, Y_train)\n",
    "tensorboard = TensorBoard(log_dir='/tmp/tboard_logs2', histogram_freq=0, write_graph=True, write_images=True)\n",
    "STEPS_PER_EPOCH = X_train.shape[0] / 32\n",
    "VALIDATION_STEPS = len(X_val) / 32\n",
    "#INPUT_SIZE = 256\n",
    "\n",
    "\n",
    "model = fcn_model(lr=.0001)\n",
    "#model.fit_generator(train_batches, steps_per_epoch=STEPS_PER_EPOCH, epochs=NUM_EPOCHS, verbose=1, callbacks=[reduce_lr])\n",
    "model.fit(X_train, Y_train, batch_size=12, epochs=NUM_EPOCHS, verbose=1, shuffle=True, validation_data=(X_val, Y_val),\n",
    "         callbacks=[model_checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
